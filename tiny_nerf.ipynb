{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLDTVWKq7-ei"
      },
      "source": [
        "##Tiny NeRF\n",
        "This is a simplied version of the method presented in *NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis*\n",
        "\n",
        "[Project Website](http://www.matthewtancik.com/nerf)\n",
        "\n",
        "[arXiv Paper](https://arxiv.org/abs/2003.08934)\n",
        "\n",
        "[Full Code](github.com/bmild/nerf)\n",
        "\n",
        "Components not included in the notebook\n",
        "*   5D input including view directions\n",
        "*   Hierarchical Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bZNXlxmEj0FC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "# Removed the line that tries to force TensorFlow 1.x\n",
        "#if IN_COLAB:\n",
        "#    %tensorflow_version 1.x\n",
        "\n",
        "#Import tensorflow\n",
        "import tensorflow as tf\n",
        "#Enable eager execution for TensorFlow 2.x\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlZyPSV51df5",
        "outputId": "b069ab96-c5cd-4ca8-9ac6-2c0ec3db9b33"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Tinynerf folder\n",
        "tinynerf_dir = '/content/drive/MyDrive/DESMAI_TALIYAJOSEPH_2025/Tinynerf'\n",
        "print(\"Contents of Tinynerf directory:\")\n",
        "!ls {tinynerf_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig7-DON_id5",
        "outputId": "2fe52e2e-d993-4080-a44b-ab5fb84d101b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of Tinynerf directory:\n",
            "Blenderllff_TF\ttiny_nerf.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# Specify Image Folder Path\n",
        "image_folder = r\"/content/drive/MyDrive/DESMAI_TALIYAJOSEPH_2025/Tinynerf/Blenderllff_TF\"\n",
        "\n",
        "# Debugging: Check if the folder exists\n",
        "if not os.path.exists(image_folder):\n",
        "    print(\"The specified folder does not exist.\")\n",
        "else:\n",
        "    print(\"Folder exists.\")\n",
        "\n",
        "# Load and Process Images\n",
        "print(f\"Image folder path: '{image_folder}' Length: {len(image_folder)}\")  # Debugging output\n",
        "all_files = os.listdir(image_folder)\n",
        "print(\"All files in the folder:\", all_files)\n",
        "\n",
        "# Filter for PNG files\n",
        "image_filenames = [f for f in all_files if f.endswith('.png')]\n",
        "print(\"Number of PNG images found:\", len(image_filenames))\n",
        "\n",
        "images = []\n",
        "for filename in image_filenames:\n",
        "    img_path = os.path.join(image_folder, filename)\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        images.append(np.array(img))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "if images:\n",
        "    images = np.stack(images, axis=0)\n",
        "    print(\"Images shape:\", images.shape)\n",
        "else:\n",
        "    print(\"No valid images loaded.\")\n",
        "\n",
        "# Camera Poses and Focal Length\n",
        "poses = np.random.rand(100, 4, 4)  # Replace with your actual poses\n",
        "focal = 138.8892067803277\n",
        "\n",
        "# Save as .npz File\n",
        "output_path = r\"/content/drive/MyDrive/DESMAI_TALIYAJOSEPH_2025/my_custom_dataset.npz\"\n",
        "np.savez_compressed(output_path, images=images, poses=poses, focal=focal)\n",
        "\n",
        "print(\"Dataset saved as my_custom_dataset.npz in\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "kZ13uoXx7GhX",
        "outputId": "fc518007-6b50-459d-aac3-72e26b043bb9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 107] Transport endpoint is not connected: '/content/drive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-2f6f465ecece>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Specify Image Folder Path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/drive'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Specify the path to your custom dataset\n",
        "dataset_path = r\"/content/drive/MyDrive/DESMAI_TALIYAJOSEPH_2025/my_custom_dataset.npz\"\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Custom dataset does not exist at the specified path.\")\n",
        "else:\n",
        "    print(\"Loading custom dataset...\")\n",
        "\n",
        "    # Load the NPZ file\n",
        "    data = np.load(dataset_path)\n",
        "\n",
        "    # Access the arrays stored in the NPZ file\n",
        "    images = data['images']\n",
        "    poses = data['poses']\n",
        "    focal = data['focal']\n",
        "\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Poses shape:\", poses.shape)\n",
        "    print(\"Focal length:\", focal)"
      ],
      "metadata": {
        "id": "idU3jAQAAHr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mTxAwgrj4yn"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#if not os.path.exists('tiny_nerf_data.npz'):\n",
        "    #!wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#import numpy as np\n",
        "\n",
        "#if not os.path.exists('tiny_nerf_data.npz'):\n",
        "    #!wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
        "\n",
        "# Now you can load the data\n",
        "#data = np.load('tiny_nerf_data.npz')"
      ],
      "metadata": {
        "id": "Q8F1oH8aUd-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Access images, poses, and focal length from the loaded data\n",
        "images = data['images']\n",
        "poses = data['poses']\n",
        "focal = data['focal']\n",
        "\n",
        "# Print information about the dataset\n",
        "print(\"Image shape:\", images.shape)  # Shape of the images array\n",
        "print(\"Poses shape:\", poses.shape)    # Shape of the poses array\n",
        "print(\"Focal length:\", focal)         # Value of the focal length\n",
        "\n",
        "# Display a few sample images from the dataset\n",
        "num_images_to_display = 5  # Number of images to display\n",
        "\n",
        "for i in range(num_images_to_display):\n",
        "    plt.figure()\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(f\"Image {i + 1}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UCeNpo6R15sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2dgdCDi-m3T"
      },
      "source": [
        "# Load Input Images and Poses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj1lof2ej0FI"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your custom dataset\n",
        "dataset_path = r\"/content/drive/MyDrive/DESMAI_TALIYAJOSEPH_2025/my_custom_dataset.npz\"  # Corrected path\n",
        "\n",
        "# Load the NPZ file using the specified path\n",
        "data = np.load(dataset_path)\n",
        ")\n",
        "images = data['images']\n",
        "poses = data['poses']\n",
        "focal = data['focal']\n",
        "H, W = images.shape[1:3]\n",
        "print(images.shape, poses.shape, focal)\n",
        "\n",
        "testimg, testpose = images[101], poses[101]\n",
        "images = images[:100,...,:3]\n",
        "poses = poses[:100]\n",
        "\n",
        "plt.imshow(testimg)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDt192E-v6i"
      },
      "source": [
        "# Optimize NeRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1avtwVoAQTu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def posenc(x):\n",
        "  rets = [x]\n",
        "  for i in range(L_embed):\n",
        "    for fn in [tf.sin, tf.cos]:\n",
        "      rets.append(fn(2.**i * x))\n",
        "  return tf.concat(rets, -1)\n",
        "\n",
        "L_embed = 6\n",
        "embed_fn = posenc\n",
        "# L_embed = 0\n",
        "# embed_fn = tf.identity\n",
        "\n",
        "def init_model(D=8, W=256):\n",
        "    relu = tf.keras.layers.ReLU()\n",
        "    dense = lambda W=W, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(3 + 3*2*L_embed,))\n",
        "    outputs = inputs\n",
        "    for i in range(D):\n",
        "        outputs = dense()(outputs)\n",
        "        if i%4==0 and i>0:\n",
        "            outputs = tf.keras.layers.concatenate([outputs, inputs], axis=-1)\n",
        "    outputs = dense(4, act=None)(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_rays(H, W, focal, c2w):\n",
        "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
        "    dirs = tf.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -tf.ones_like(i)], -1)\n",
        "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
        "    rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
        "    return rays_o, rays_d\n",
        "\n",
        "\n",
        "\n",
        "def render_rays(network_fn, rays_o, rays_d, near, far, N_samples, rand=False):\n",
        "\n",
        "    def batchify(fn, chunk=1024*32):\n",
        "        return lambda inputs : tf.concat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
        "\n",
        "    # Compute 3D query points\n",
        "    z_vals = tf.linspace(near, far, N_samples)\n",
        "    if rand:\n",
        "      z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
        "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
        "\n",
        "    # Run network\n",
        "    pts_flat = tf.reshape(pts, [-1,3])\n",
        "    pts_flat = embed_fn(pts_flat)\n",
        "    raw = batchify(network_fn)(pts_flat)\n",
        "    raw = tf.reshape(raw, list(pts.shape[:-1]) + [4])\n",
        "\n",
        "    # Compute opacities and colors\n",
        "    sigma_a = tf.nn.relu(raw[...,3])\n",
        "    rgb = tf.math.sigmoid(raw[...,:3])\n",
        "\n",
        "    # Do volume rendering\n",
        "    dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([1e10], z_vals[...,:1].shape)], -1)\n",
        "    alpha = 1.-tf.exp(-sigma_a * dists)\n",
        "    weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
        "\n",
        "    rgb_map = tf.reduce_sum(weights[...,None] * rgb, -2)\n",
        "    depth_map = tf.reduce_sum(weights * z_vals, -1)\n",
        "    acc_map = tf.reduce_sum(weights, -1)\n",
        "\n",
        "    return rgb_map, depth_map, acc_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TSAyVcKAiyI"
      },
      "source": [
        "Here we optimize the model. We plot a rendered holdout view and its PSNR every 50 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XurcHoCj0FQ"
      },
      "outputs": [],
      "source": [
        "model = init_model()\n",
        "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
        "\n",
        "N_samples = 64\n",
        "N_iters = 1000\n",
        "psnrs = []\n",
        "iternums = []\n",
        "i_plot = 25\n",
        "\n",
        "import time\n",
        "t = time.time()\n",
        "for i in range(N_iters+1):\n",
        "\n",
        "    img_i = np.random.randint(images.shape[0])\n",
        "    target = images[img_i]\n",
        "    pose = poses[img_i]\n",
        "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
        "    with tf.GradientTape() as tape:\n",
        "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples, rand=True)\n",
        "        loss = tf.reduce_mean(tf.square(rgb - target))\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    if i%i_plot==0:\n",
        "        print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
        "        t = time.time()\n",
        "\n",
        "        # Render the holdout view for logging\n",
        "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
        "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
        "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
        "\n",
        "        psnrs.append(psnr.numpy())\n",
        "        iternums.append(i)\n",
        "\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(rgb)\n",
        "        plt.title(f'Iteration: {i}')\n",
        "        plt.subplot(122)\n",
        "        plt.plot(iternums, psnrs)\n",
        "        plt.title('PSNR')\n",
        "        plt.show()\n",
        "\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZLEFNox_UVK"
      },
      "source": [
        "# Interactive Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92jHDI7j0FT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from ipywidgets import interactive, widgets\n",
        "\n",
        "\n",
        "trans_t = lambda t : tf.convert_to_tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0],\n",
        "    [0,0,1,t],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "rot_phi = lambda phi : tf.convert_to_tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,tf.cos(phi),-tf.sin(phi),0],\n",
        "    [0,tf.sin(phi), tf.cos(phi),0],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "rot_theta = lambda th : tf.convert_to_tensor([\n",
        "    [tf.cos(th),0,-tf.sin(th),0],\n",
        "    [0,1,0,0],\n",
        "    [tf.sin(th),0, tf.cos(th),0],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "\n",
        "def pose_spherical(theta, phi, radius):\n",
        "    c2w = trans_t(radius)\n",
        "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
        "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
        "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
        "    return c2w\n",
        "\n",
        "\n",
        "def f(**kwargs):\n",
        "    c2w = pose_spherical(**kwargs)\n",
        "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
        "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "    img = np.clip(rgb,0,1)\n",
        "\n",
        "    plt.figure(2, figsize=(20,6))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
        "    value=v,\n",
        "    min=mi,\n",
        "    max=ma,\n",
        "    step=.01,\n",
        ")\n",
        "\n",
        "names = [\n",
        "    ['theta', [100., 0., 360]],\n",
        "    ['phi', [-30., -90, 0]],\n",
        "    ['radius', [4., 3., 5.]],\n",
        "]\n",
        "\n",
        "interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
        "output = interactive_plot.children[-1]\n",
        "output.layout.height = '350px'\n",
        "interactive_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpKhAn2a__Iu"
      },
      "source": [
        "# Render 360 Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sg4aV0cmVPs"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "for th in tqdm(np.linspace(0., 360., 120, endpoint=False)):\n",
        "    c2w = pose_spherical(th, -30., 4.)\n",
        "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
        "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "    frames.append((255*np.clip(rgb,0,1)).astype(np.uint8))\n",
        "\n",
        "import imageio\n",
        "f = 'video.mp4'\n",
        "imageio.mimwrite(f, frames, fps=30, quality=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ_ms-YMyFly"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls autoplay loop>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvR-v3uzCFYQ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT38DMfyCICr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tiny_nerf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-tf115",
      "language": "python",
      "name": "venv-tf115"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}